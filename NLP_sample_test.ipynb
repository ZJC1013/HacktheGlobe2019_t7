{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import html\n",
    "import re\n",
    "import time\n",
    "import spacy\n",
    "import string\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = '/Users/jasonzhou/Downloads/Hack_data'\n",
    "abbv_dir_1 = '/Users/jasonzhou/Downloads/NLP_origin/A1/Wordlists/abbrev.english'\n",
    "abbv_dir_2 = '/Users/jasonzhou/Downloads/NLP_origin/A1/Wordlists/pn_abbrev.english'\n",
    "clitics_dir = '/Users/jasonzhou/Downloads/NLP_origin/A1/Wordlists/clitics'\n",
    "stop_dir = '/Users/jasonzhou/Downloads/NLP_origin/A1/Wordlists/StopWords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc1( comment , steps=range(1,11)):\n",
    "    ''' This function pre-processes a single comment\n",
    "\n",
    "    Parameters:\n",
    "        comment : string, the body of a comment\n",
    "        steps   : list of ints, each entry in this list corresponds to a preprocessing step\n",
    "\n",
    "    Returns:\n",
    "        modComm : string, the modified comment\n",
    "    '''\n",
    "    # print(comment)\n",
    "    modComm = ''\n",
    "    if 1 in steps:\n",
    "        #Remove all newline characters\n",
    "        # comment = comment.replace(\"\\n\",\" \")\n",
    "        comment = ' '.join([line.strip() for line in comment.strip().splitlines()])\n",
    "    if 2 in steps:\n",
    "        #Replace HTML character codes (i.e., &...;) with their ASCII equivalent\n",
    "        comment = html.unescape(comment)\n",
    "    if 3 in steps:\n",
    "        #Remove all URLs (i.e., tokens beginning with http or www)\n",
    "        comment = re.sub(r'http\\S+', '', comment, flags=re.MULTILINE)\n",
    "        comment = re.sub(r'www\\S+', '', comment, flags=re.MULTILINE)\n",
    "        comment = re.sub(r'@\\S+','',comment, flags=re.MULTILINE)\n",
    "        # comment = re.sub(r'(?:(?:www|http|https):\\/\\/)?([-a-zA-Z0-9.]{2,256}\\.[a-z]{2,4})\\b(?:\\/[-a-zA-Z0-9@:%_\\+.~#?&//=]*)?',\"\",comment,flags=re.MULTILINE)\n",
    "        # reference: https://stackoverflow.com/questions/38804425/remove-urls-from-a-text-file\n",
    "    if 4 in steps:\n",
    "        abbrev_1 = open(abbv_dir_1).read().split('\\n')\n",
    "        abbrev_2 = open(abbv_dir_2).read().split('\\n')\n",
    "        abbreviation = abbrev_1 + abbrev_2\n",
    "        if '' in abbreviation:\n",
    "            abbreviation.remove('')\n",
    "        # punctuation = \"!\\\"#$%&()*+,\\\\-./:;<=>?@[]^_{|}~\"\n",
    "\n",
    "        temp = ''\n",
    "        i = 0\n",
    "        while i < len(comment):\n",
    "            isException = False\n",
    "            if i == 0 or not(comment[i-1].isalpha()):\n",
    "                for word in abbreviation:\n",
    "                    if comment[i:].lower().startswith(word.lower()):\n",
    "                        temp += comment[i:i+len(word)]\n",
    "                        i += len(word)\n",
    "                        isException = True\n",
    "                        break\n",
    "            if not(isException):\n",
    "                if comment[i] in string.punctuation and comment[i] != \"'\":\n",
    "                    temp += ' '\n",
    "                    while i < len(comment) and (comment[i] in string.punctuation and comment[i] != \"'\"):\n",
    "                        temp += comment[i]\n",
    "                        i += 1\n",
    "                    temp += ' '\n",
    "                else:\n",
    "                    temp += comment[i]\n",
    "                    i += 1\n",
    "\n",
    "        comment = temp.replace('  ', ' ')\n",
    "\n",
    "    if 5 in steps:\n",
    "        clitics = open(clitics_dir).read().split('\\n')\n",
    "        # clitics.append(\"'t\")\n",
    "        clitics.append(\"s'\")\n",
    "        for word in clitics:\n",
    "            if word == \"s'\":\n",
    "                comment = comment.replace(word,\"s '\")\n",
    "            else:\n",
    "                comment = comment.replace(word,\" \"+word)\n",
    "        # print(comment)\n",
    "\n",
    "    if 6 in steps:\n",
    "        # print(comment)\n",
    "        stop_words = open(stop_dir).read().split('\\n')\n",
    "        stop_words = list(filter(('').__ne__, stop_words))\n",
    "        comment = comment.split(\" \")\n",
    "        comment = list(filter(('').__ne__, comment))\n",
    "        temp = ''\n",
    "        # print(comment)\n",
    "        for word in comment:\n",
    "            if word.lower() not in stop_words:\n",
    "                temp += word + ' '\n",
    "        # print(temp)\n",
    "        comment = temp\n",
    "\n",
    "    if 7 in steps:\n",
    "        utt = nlp(comment)\n",
    "        temp = ''\n",
    "        for token in utt:\n",
    "            if token.lemma_.startswith('-'):\n",
    "                temp += token.text\n",
    "            else:\n",
    "                temp += token.lemma_\n",
    "            temp += ' '\n",
    "        # print(temp)\n",
    "        comment = temp\n",
    "\n",
    "    if 8 in steps:\n",
    "        comment = comment.lower()\n",
    "\n",
    "    if 9 in steps:\n",
    "        comment = comment.split(\" \")\n",
    "        comment = list(filter(('').__ne__, comment))\n",
    "        temp = ''\n",
    "        for word in comment:\n",
    "            if word.isalpha():\n",
    "                temp += word + ' '\n",
    "        comment = temp\n",
    "\n",
    "    modComm = comment\n",
    "    return modComm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildVolcab(data):\n",
    "    totalVolcab = []\n",
    "    for tweet in data:\n",
    "        volcab = {}\n",
    "        sent = tweet.split(' ')\n",
    "        for word in sent:\n",
    "            if word not in volcab.keys():\n",
    "                volcab[word] = 1\n",
    "            else:\n",
    "                volcab[word] += 1\n",
    "        totalVolcab.append(volcab)\n",
    "    return totalVolcab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildwordList(totalVolcab):\n",
    "    wordList = []\n",
    "    for volcab in totalVolcab:\n",
    "        for word in volcab.keys():\n",
    "            if word not in wordList:\n",
    "                wordList.append(word)\n",
    "    return wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildMatrix(wordList, totalVolcab):\n",
    "    matrix = np.zeros((len(totalVolcab),len(wordList)))\n",
    "    for i, volcab in enumerate(totalVolcab):\n",
    "        for j, key_word in enumerate(wordList):\n",
    "            if key_word in volcab.keys():\n",
    "                matrix[i][j] = volcab[key_word]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/jasonzhou/Downloads/Hack_data/.DS_Store\n",
      "Processing /Users/jasonzhou/Downloads/Hack_data/training_1600000_processed_noemoticon.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "19999\n",
      "29999\n",
      "39999\n",
      "49999\n",
      "59999\n",
      "69999\n",
      "79999\n",
      "89999\n",
      "99999\n",
      "100000\n",
      "100000\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "for subdir, dirs, files in os.walk(indir):\n",
    "    for file in files:\n",
    "        fullFile = os.path.join(subdir, file)\n",
    "        print( \"Processing \" + fullFile)\n",
    "\n",
    "        scores, sents = [], []\n",
    "        if not file.startswith('.DS_Store'):\n",
    "            df = pd.read_csv(fullFile,sep='delimiter',header=None)\n",
    "            indices = np.arange(len(df))\n",
    "            np.random.shuffle(indices)\n",
    "            tweet = df.iloc[0,0].split(',')[5]\n",
    "            j = 0\n",
    "            for i in range(100000):\n",
    "                j += 1\n",
    "                if j >= 10000:\n",
    "                    print(i)\n",
    "                    j = 0\n",
    "                index = indices[i]\n",
    "                tweet = df.iloc[index,0].split(',')[5]\n",
    "                tweet = tweet.lstrip('\\\"')\n",
    "                tweet = tweet.rstrip('\\\"')\n",
    "\n",
    "                sent = preproc1(tweet,range(1,10))\n",
    "                sents.append(sent)\n",
    "\n",
    "                score = df.iloc[index,0].split(',')[0]\n",
    "                score = score.lstrip('\\\"')\n",
    "                score = score.rstrip('\\\"')\n",
    "                score = int(score) - 2\n",
    "                scores.append(score)\n",
    "\n",
    "    print(len(scores))\n",
    "    print(len(sents))\n",
    "    print(len(scores) == len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalVolcab = buildVolcab(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = buildwordList(totalVolcab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = buildMatrix(wordList, totalVolcab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 41186)\n",
      "(100000, 1)\n",
      "(100000, 41187)\n"
     ]
    }
   ],
   "source": [
    "print(matrix.shape)\n",
    "scoreMatrix = np.array(scores).reshape((len(scores),1))\n",
    "print(scoreMatrix.shape)\n",
    "fullMatrix = np.concatenate((matrix,scoreMatrix),axis=1)\n",
    "print(fullMatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlookupDict(fullMatrix, wordList):\n",
    "    lookupDict = {}\n",
    "    for i, word in enumerate(wordList):\n",
    "        if word not in lookupDict.keys():\n",
    "            word_scores = (fullMatrix[:,i].T.dot(fullMatrix[:,-1]) / sum(fullMatrix[:,i]))\n",
    "            lookupDict[word] = word_scores\n",
    "    return lookupDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookupDict = getlookupDict(fullMatrix, wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(sentence, lookupDict):\n",
    "    sum_score = 0\n",
    "    sent = preproc1(sentence,range(1,10))\n",
    "    sent_list = sent.split(' ')\n",
    "    for word in sent_list:\n",
    "        if word in lookupDict.keys():\n",
    "            sum_score += lookupDict[word]\n",
    "            \n",
    "    return sum_score / len(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fullMatrix[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.4367535884618149\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I am so thrilled to see you and wish we made an awesome team at the hackathon\"\n",
    "print(\"score: \", getScore(test_sentence,lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  -0.2560452650625948\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"If I had pulled my wife and daughter closer, they wouldn't fall into the crack\"\n",
    "print(\"score: \", getScore(test_sentence,lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.22569599999999998\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Well, the ground is shaking, vertically and horizontally\"\n",
    "print(\"score: \", getScore(test_sentence,lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  -0.22440914922701424\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Did you see any signs of where the crack would be before it happened\"\n",
    "print(\"score: \", getScore(test_sentence,lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  -0.4549147663551402\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Not really. It was too chaotic for me to notice that\"\n",
    "print(\"score: \", getScore(test_sentence,lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.03991694659635183\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Do you think your family would expect that from you\"\n",
    "print(\"score: \", getScore(test_sentence,lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  -0.22947730464359686\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"True. You know what, I am feeling much better now\"\n",
    "print(\"score: \", getScore(test_sentence,lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  -0.4894487019807366\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"At the time of the assult, I felt frightened, I felt angry, confused, roughly I don't know what was happening to me\"\n",
    "print(\"score: \", getScore(test_sentence,lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  -0.5873432192122001\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I'm emotional, devastated and I'm distressed, because I can't find anywhere to stay\"\n",
    "print(\"score: \", getScore(test_sentence,lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open('lookup_dict.json','w')\n",
    "fout.write(json.dumps(lookupDict))\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore_display(sentence, lookupDict):  \n",
    "    sum_score = 0\n",
    "    sent = preproc1(sentence,range(1,10))\n",
    "    sent_list = sent.split(' ')\n",
    "    sent_list = list(filter(('').__ne__, sent_list))\n",
    "    word_score = {}\n",
    "    for word in sent_list:\n",
    "        if word in lookupDict.keys():\n",
    "            sum_score += lookupDict[word]\n",
    "            if word not in word_score.keys():\n",
    "                word_score[word] = lookupDict[word]\n",
    "    #print(sorted(word_score.items()))\n",
    "    count = 0\n",
    "    for key, value in sorted(word_score.items()):\n",
    "        if value <= -0.5:\n",
    "            count += 1\n",
    "            if count <= 2:\n",
    "                print(\"%s: %.3f\" %(key, value))\n",
    "            else:\n",
    "                break\n",
    "    return sum_score / len(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lookupDict = json.load(open('lookup_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devastate: -2.000\n",
      "emotional: -0.800\n",
      "score:  -0.7205170291820508\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I am emotional, devastated and I am distressed, because I cannot find anywhere to stay\"\n",
    "print(\"score: \", getScore_display(test_sentence,lookupDict,local=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry: -1.404\n",
      "confused: -1.125\n",
      "score:  -0.5342604021608035\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"At the time of the assult, I felt frightened, I felt angry, confused, roughly I don't know what was happening to me\"\n",
    "print(\"score: \", getScore_display(test_sentence,lookupDict,local=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('awesome', 1.1904761904761905), ('hackathon', 2.0), ('team', 0.4383561643835616), ('thrilled', 0.8), ('wish', -1.1528150134048258)]\n",
      "wish: -1.153\n",
      "score:  0.6552034682909852\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I am so thrilled to see you and wish we can make an awesome team at the hackathon\"\n",
    "print(\"score: \", getScore_display(test_sentence,lookupDict,local=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('awesome', 1.1904761904761905), ('hackathon', 2.0), ('team', 0.4383561643835616), ('thrilled', 0.8)]\n",
      "score:  1.107208088714938\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I am so thrilled to see you and we will make an awesome team at the hackathon\"\n",
    "print(\"score: \", getScore_display(test_sentence,lookupDict,local=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bad', -1.2114285714285715)]\n",
      "bad: -1.211\n",
      "score:  -1.2114285714285715\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"really bad\"\n",
    "print(\"score: \", getScore_display(test_sentence,local_lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('terrible', -1.4901960784313726)]\n",
      "terrible: -1.490\n",
      "score:  -1.4901960784313726\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Terrible.\"\n",
    "print(\"score: \", getScore_display(test_sentence,local_lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bother', -1.044776119402985), ('nightmare', -1.368421052631579)]\n",
      "bother: -1.045\n",
      "nightmare: -1.368\n",
      "score:  -1.2065985860172819\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"The nightmares kept bothering me.\"\n",
    "print(\"score: \", getScore_display(test_sentence,local_lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('close', -0.8494983277591973), ('crack', -0.058823529411764705), ('fall', -0.8636363636363636), ('pull', -0.49122807017543857), ('wife', 0.09345794392523364)]\n",
      "close: -0.849\n",
      "fall: -0.864\n",
      "score:  -0.4339456694115061\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"My wife. If I had pulled her closer, she would not fall into the crack.\"\n",
    "print(\"score: \", getScore_display(test_sentence,local_lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('husband', -0.32653061224489793), ('terrible', -1.4901960784313726)]\n",
      "terrible: -1.490\n",
      "score:  -0.9083633453381352\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I am a terrible husband.\"\n",
    "print(\"score: \", getScore_display(test_sentence,local_lookupDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
